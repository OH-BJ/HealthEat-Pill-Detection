import os
import glob
import json
import random
from collections import defaultdict
from sklearn.model_selection import train_test_split

# =================================================================
# 1. ì„¤ì • ë³€ìˆ˜
# =================================================================
# ì›ë³¸ ì´ë¯¸ì§€ì™€ ë¼ë²¨(.txt) íŒŒì¼ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬. í•´ë‹¹ í´ë”ì— ë¶„í•  ëª©ë¡ íŒŒì¼ì„ ì €ì¥í•˜ì—¬ YOLO data.yamlì—ì„œ ì°¸ì¡°í•¨.
DATA_DIR = 'data/yolo' 

# ë¶„í•  ë¹„ìœ¨
TRAIN_RATIO = 0.7
VAL_RATIO = 0.15
TEST_RATIO = 0.15 # í•©ê³„ëŠ” 1.0 ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

# ì‹œë“œ ì„¤ì • (ì¬í˜„ì„± í™•ë³´)
RANDOM_SEED = 42

# =================================================================
# 2. ì¸µí™” ë¶„í•  ë¡œì§
# =================================================================

def load_and_group_data():
    """
    ëª¨ë“  ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ìˆ˜ì§‘í•˜ê³ , ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ í´ë˜ìŠ¤ IDë¥¼ ì¶”ì¶œí•˜ì—¬
    ì´ë¯¸ì§€ ê²½ë¡œë“¤ì„ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤ (ì¸µí™” í‘œì§‘ì„ ìœ„í•¨).
    """
    label_files = glob.glob(os.path.join(DATA_DIR, 'labels', '*.txt'))
    
    # ë”•ì…”ë„ˆë¦¬: {í´ë˜ìŠ¤_ID: [í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡]}
    data_by_class = defaultdict(list)
    
    all_image_paths = []

    print(f"ì´ {len(label_files)}ê°œì˜ ë¼ë²¨ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.")

    for label_path in label_files:
        # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. (ì˜ˆ: .../images/0001.png)
        img_filename = os.path.basename(label_path).replace('.txt', '.png')
        img_path = os.path.join(DATA_DIR, 'images', img_filename)
                
        all_image_paths.append(img_path)
        
        # ë¼ë²¨ íŒŒì¼ì—ì„œ í¬í•¨ëœ í´ë˜ìŠ¤ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        try:
            with open(label_path, 'r') as f:
                for line in f:
                    if line.strip():
                        # YOLO ë¼ë²¨ í˜•ì‹: class_id x_c y_c w h (class_idëŠ” 0ë¶€í„° ì‹œì‘)
                        class_id = int(line.split()[0])
                        # ê° í´ë˜ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì¶”ê°€
                        data_by_class[class_id].append(img_path)
        except Exception as e:
            print(f"ë¼ë²¨ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({label_path}): {e}")
            continue

    # ì¤‘ë³µëœ ì´ë¯¸ì§€ ê²½ë¡œ ì œê±° (í•˜ë‚˜ì˜ ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ í´ë˜ìŠ¤ì— í¬í•¨ë  ìˆ˜ ìˆìŒ)
    unique_image_paths = sorted(list(set(all_image_paths)))
    
    # ê° ì´ë¯¸ì§€ì— í¬í•¨ëœ ëª¨ë“  í´ë˜ìŠ¤ ID ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (Stratify ê¸°ì¤€)
    image_class_labels = []
    for img_path in unique_image_paths:
        label_path = img_path.replace('images', 'labels').replace('.png', '.txt')
        classes = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    if line.strip():
                        classes.append(line.split()[0])
        # ì´ë¯¸ì§€ë¥¼ ëŒ€í‘œí•˜ëŠ” í´ë˜ìŠ¤ ë¼ë²¨(ë“¤)ì„ ë¬¸ìì—´ë¡œ ê²°í•© (stratify ì¸ììš©)
        image_class_labels.append(','.join(sorted(classes))) 
        
    return unique_image_paths, image_class_labels

def save_list_files(paths, filename):
    """ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    file_path = os.path.join(DATA_DIR, filename)
    
    # YOLO í˜•ì‹ì— ë§ê²Œ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ROOT_DATA_DIR í•˜ìœ„)
    relative_paths = [os.path.relpath(p, DATA_DIR) for p in paths]
    
    with open(file_path, 'w') as f:
        f.write('\n'.join(relative_paths))
    print(f"âœ… {filename} íŒŒì¼ ì €ì¥ ì™„ë£Œ: ì´ {len(paths)}ê°œ ê²½ë¡œ")
    return file_path


def split_data_and_save():
    """ë©”ì¸ ë¶„í•  ì‹¤í–‰ í•¨ìˆ˜"""
    
    all_paths, class_labels = load_and_group_data()
    
    if not all_paths:
        print("ğŸš¨ ì˜¤ë¥˜: ë°ì´í„°ì…‹ í´ë”ì—ì„œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. Trainê³¼ ì„ì‹œ (Val + Test) ë¶„í• 
    # Stratify ì¸ìë¡œ í´ë˜ìŠ¤ ë¼ë²¨ì„ ì‚¬ìš©í•˜ì—¬ ì¸µí™” ë¶„í• 
    X_temp, X_train, y_temp, y_train = train_test_split(
        all_paths, class_labels, 
        test_size=TRAIN_RATIO, 
        random_state=RANDOM_SEED, 
        stratify=class_labels
    )

    # 2. ì„ì‹œ ì„¸íŠ¸ë¥¼ Valê³¼ Testë¡œ ë¶„í• 
    # Test ì„¸íŠ¸ ë¹„ìœ¨ ê³„ì‚°: TEST_RATIO / (VAL_RATIO + TEST_RATIO)
    test_size_ratio = TEST_RATIO / (VAL_RATIO + TEST_RATIO)

    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, 
        test_size=test_size_ratio, 
        random_state=RANDOM_SEED, 
        stratify=y_temp
    )
    
    # 3. ê²°ê³¼ ì €ì¥
    save_list_files(X_train, 'train.txt')
    save_list_files(X_val, 'val.txt')
    save_list_files(X_test, 'test.txt') # Test ì„¸íŠ¸ ê²½ë¡œ ì €ì¥
    
    print("\n--- ë°ì´í„° ë¶„í•  ê²°ê³¼ ---")
    print(f"ì´ ë°ì´í„°: {len(all_paths)}ê°œ")
    print(f"Train ì„¸íŠ¸: {len(X_train)}ê°œ ({len(X_train)/len(all_paths):.1%})")
    print(f"Validation ì„¸íŠ¸: {len(X_val)}ê°œ ({len(X_val)/len(all_paths):.1%})")
    print(f"Test ì„¸íŠ¸: {len(X_test)}ê°œ ({len(X_test)/len(all_paths):.1%})")
    print("-------------------------")


if __name__ == '__main__':
    # scikit-learnì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ì„¤ì¹˜ ë©”ì‹œì§€ ì¶œë ¥
    try:
        import sklearn
    except ImportError:
        print("ğŸš¨ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬: `scikit-learn`ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì‹­ì‹œì˜¤: pip install scikit-learn")
        exit()
        
    split_data_and_save()
